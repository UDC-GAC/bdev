\documentclass[10pt, a4paper, twoside, titlepage]{article}

\usepackage[a4paper, top=4cm, bottom=4cm, left=3.2cm, right=3.2cm]{geometry}
\usepackage[latin1]{inputenc}
\usepackage[dvips]{graphicx}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage[notindex,nottoc,notlot,notlof]{tocbibind}
\usepackage[hyphens]{url}
\usepackage{colortbl}
\usepackage{wrapfig}
\usepackage{eurosym}
\usepackage{breakurl}
\usepackage[hyperpageref]{backref} 
\usepackage{lscape}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{footnote}
\usepackage{threeparttable}
\usepackage{rotating} 
\usepackage{array}
\usepackage{booktabs}  
\usepackage{multicol}
\usepackage{pdflscape}
\usepackage{afterpage}
\usepackage{listings}
\usepackage{dirtree}
\usepackage{color}
\usepackage{nameref}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,citecolor=red,urlcolor=blue,filecolor=red}

\lstset{
  language=[LaTeX]TeX,
  basicstyle=\ttfamily,
  breaklines=true,
  columns=fullflexible
}

\makesavenoteenv{tabular}
\makesavenoteenv{table}

\usepackage{tikz}
\usetikzlibrary{calc,trees,positioning,arrows,chains,shapes.geometric,%
    decorations.pathreplacing,decorations.pathmorphing,shapes,%
    matrix,shapes.symbols}

\tikzset{
>=stealth',
  punktchain/.style={
    rectangle, 
    rounded corners, 
    draw=gray, thin,
    text width=12em, 
    minimum height=1.2em, 
    text centered, 
    thin,inner sep=0pt, outer sep=0pt,
    on chain},
  line/.style={draw, thin, <-},
  element/.style={
    tape,
    top color=white,
    bottom color=blue!50!black!60!,
    minimum width=8em,
    draw=blue!40!black!90, thin,
    text width=10em, 
    minimum height=3.5em, 
    text centered, 
    on chain},
  every join/.style={->, thin,shorten >=1pt},
  decoration={brace},
  tuborg/.style={decorate},
  tubnode/.style={midway, right=2pt},
}

\title{Big Data Evaluator: User Guide}

\author{Jorge Veiga, Roberto R. Expósito, Jonatan Enes, Guillermo L. Taboada and Juan Touriño \\
Computer Architecture Group\\ University of A Coruña}

\newcommand{\hadoopversion}{2.9.2}
\newcommand{\flameversion}{1.2}

\begin{document}

\newcommand{\method}{BDEv}
\newcommand{\methodlarge}{Big Data Evaluator}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\pagestyle{empty}


\begin{center}
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.75\textwidth]{./fig/udc.png}
	\includegraphics[width=0.75\textwidth]{./fig/cag-eng.png}
\end{figure}

\HRule \\[0.4cm]
{ \huge \bfseries \methodlarge: User Guide}\\[0.2cm] % Title of your document
\HRule \\[1.5cm]

\Large Authors:\\
Jorge Veiga, Roberto R. Expósito, Jonatan Enes, Guillermo L. Taboada and Juan Touriño \\
\vspace*{1cm}

{\Large January X, 2020}\\[1cm]

\vfill

\end{center}

\clearpage

\tableofcontents

\clearpage

\section{Overview}

The \methodlarge~(\method)\footnote{\method~has evolved from MREv, a MapReduce Evaluation tool aimed to compare the performance of HPC-oriented MapReduce solutions. \method~also evaluates new types of Big Data frameworks like Spark and Flink.} is an benchmarking tool that extracts valuable information about the performance, resource utilization, energy efficiency and microarchitectural behaviour of several Big Data frameworks. It supports different workloads to perform the comparisons, including micro-benchmarks and real-world applications.

\method~uses a wide range of user-defined parameters that unify of the configuration the frameworks, ensuring fair comparisons between them. In each experiment, the user can select the frameworks to launch and the workloads to execute, testing their scalability by using several cluster sizes. The user can also determine the number of times each workload is executed in order to obtain statistical information.

This tool is distributed as free software under the MIT license and is publicly available to download at \url{http://bdev.des.udc.es}.

\section{Citation}

If you have used \method~in your research, please cite our work using the following reference:
\begin{itemize}
	\item Jorge Veiga, Jonatan Enes, Roberto R. Expósito and Juan Touriño. BDEv 3.0: Energy efficiency and microarchitectural characterization of Big Data processing frameworks. Future Generation Computer Systems, vol. 86, pages 565-581. September 2018.
\end{itemize}

\section{Framework download}

By default, Big Data processing frameworks are stored in the \path{$BDEv_HOME/solutions/dist} directory. 
\method~includes the following frameworks within its distribution 
package:

\begin{itemize}
\item Hadoop-YARN version \hadoopversion
\item Flame-MR version \flameversion
\end{itemize}

The rest of the frameworks and versions are not included in order to keep the \method~distribution into a reasonable size. To use one of them in 
the evaluations, the user must download and store it in the following 
directory:

\begin{small}
\begin{lstlisting}
$BDEv_HOME/solutions/dist/$FRAMEWORK_NAME/$FRAMEWORK_VERSION
\end{lstlisting}
\end{small}

% $

Where \path{$FRAMEWORK_NAME} and \path{$FRAMEWORK_VERSION} must be the framework name 
and version, respectively, as they appear in the \path{$BDEv_HOME/experiment/solutions.lst} file.

\section{Configuration of the experiments}

The configuration of a experiment affects the following files:

\begin{itemize}[itemsep=1pt]
	\item hostfile
	\item bdev-conf.sh
	\item system-conf.sh
	\item experiment-conf.sh
	\item core-conf.sh
	\item hdfs-conf.sh
	\item mapred-conf.sh
	\item yarn-conf.sh
	\item solutions-conf.sh
	\item solutions.lst
	\item benchmarks.lst
	\item cluster\_sizes.lst
\end{itemize}

The environment variables and the configuration files are explained below, including the default values of the parameters.

\paragraph{Environment variables} There are two environment variables that \method~uses to know where to find the configuration of the experiments. First, the \texttt{EXP\_DIR} variable determines the directory that contains the configuration files mentioned above. This feature enables to set up different evaluations by means of several experiment directories. If this variable is not set, the value taken by default is \path{$BDEv_HOME/experiment}.
Second, the \texttt{HOSTFILE} variable contains the path to the hostfile. If this variable is not set, the value taken by default is \path{$EXP_DIR/hostfile}. 

\begin{small}
\begin{lstlisting}
export EXP_DIR=$BDEv_HOME/experiment
export HOSTFILE=$EXP_DIR/hostfile
\end{lstlisting}
\end{small}

\paragraph{hostfile} This file lists the computing nodes that will be used in the experiments. The first line of the file will be the master, and the remaining lines will be the slaves. NOTE: the ``localhost'' host name can only be used if the evaluation is going to run on local, instead the user must specify the hostname that corresponds to the host.

\paragraph{bdev-conf.sh} This file contains some parameters that configure the behaviour of \method~along the experiments. Most importantly, the user can indicate which monitoring tools to activate:

\begin{itemize}
\item[] \texttt{ENABLE\_PLOT}: generates performance graphs with the execution time of the workloads
\item[] \texttt{ENABLE\_STAT}: monitors resource usage using the dstat tool
\item[] \texttt{ENABLE\_ILO}: records system power consumption via the HPE iLO interface (requires its previous instalation)
\item[] \texttt{ENABLE\_RAPL}: measures CPU and memory power consumption using a built-in RAPL tool implemented with PAPI
\item[] \texttt{ENABLE\_OPROFILE}: counts microarchitecture-level events via Oprofile
\item[] \texttt{ENABLE\_BDWATCHDOG}: monitors resource usage using the BDWatchdog framework\footnote{\url{http://bdwatchdog.dec.udc.es}}
\end{itemize}


Along with the enablement of these tools and its related configuration parameters, further properties are also contained in this file. \texttt{DEFAULT\_TIMEOUT} defines the maximum execution time of a workload used by default. Those which run above this limit will be killed, and the execution of the solution will be finished. Of course, this \method~feature can be disabled by setting \texttt{DEFAULT\_TIMEOUT} to 0. Finally, the directory where \method~will write the results of the experiment can also be configured by using the \texttt{OUT\_DIR} variable. If this variable is not set, the value taken by default is \path{$PWD/BDEv_OUT}. %$


\paragraph{system-conf.sh} This file contains the parameters related to the system where \method~is being run. Some of them are automatically detected from the system, but can also be tuned by the user in order to maximize the leveraging of the system resources.

\paragraph{experiment-conf.sh} This file sets the configuration of the benchmarks, including the problem size and additional parameters, as well as the number of times each one is executed. Moreover, it also contains the \texttt{METHOD\_COMMAND} variable, which contains the action to run in batch mode during the command benchmark. Additionally, \texttt{METHOD\_PREPARE\_COMMAND} is called to set up the input datasets needed for \texttt{METHOD\_COMMAND}. This enables to perform accurate performance and resource utilization monitoring, without taking into account the data generation or the copy to HDFS. This file also allows to configure specific timeouts for each benchmark.

\paragraph{core-conf.sh} This file contains configuration parameters which are related to the core-site.xml file of Hadoop configuration.


\paragraph{hdfs-conf.sh} This file contains configuration parameters which are related to the hdfs-site.xml file of Hadoop configuration.

\paragraph{mapred-conf.sh} This file contains configuration parameters which are related to the mapred-site.xml file of Hadoop configuration.

\paragraph{yarn-conf.sh} This file contains configuration parameters which are related to the yarn-site.xml file of Hadoop configuration.

\paragraph{solutions-conf.sh} This file contains configuration parameters which are specific to each solution, as well as some variables for Apache Mahout and Apache Hive.

\paragraph{solutions.lst} This file contains the solutions to be used in the experiment, specifying the framework, its version and the network interface to be configured. From version 3.3 onwards, \method~automatically switches to command mode if no solution is selected in this file. This can be useful to run any application in the cluster while taking advantage of all the monitoring features provided by \method~.

\paragraph{benchmarks.lst} This file contains the benchmarks to be used in the experiment. 

\paragraph{cluster\_sizes.lst} This file contains the cluster sizes with which the user wants to run the experiments. Additionally, the cluster size can be set to the maximum number of nodes available.

\section{Execution}

The following command starts the experiments:

\begin{small}
\begin{lstlisting}
bash BDEv/bin/run.sh
\end{lstlisting}
\end{small}

\section{Evaluation Outcomes}

The results from the execution will be found in the \texttt{\$OUT\_DIR} directory, having the structure shown in Figure \ref{fig:out_structure}.

\let\oldDTcomment\DTcomment
\renewcommand{\DTcomment}{\small \oldDTcomment}

\DTsetlength{0.2em}{0.6em}{0.2em}{0.4pt}{3pt}

\begin{figure}[t]
\dirtree{%
.1 report\_BDEv\_27\_10\_17-00-00.
.2 gen\_graphs.sh\DTcomment{Script to generate all resource/RAPL graphs}. 
.2 hostfile\DTcomment{Nodes used in the evaluation}.
.2 hostfile.gbe\DTcomment{GbE nodes used in the evaluation}.
.2 hostfile.ipoib\DTcomment{IPoIB nodes used in the evaluation}.
.2 log\DTcomment{Execution log}.
.2 summary\DTcomment{Experiments configuration and main results}.
.2 5\DTcomment{Output directory for cluster size 5}.
.3 Hadoop-\hadoopversion-GbE\DTcomment{Output directory for Hadoop-\hadoopversion-GbE}.
.3 Hadoop-\hadoopversion-IPoIB\DTcomment{Output directory for Hadoop-\hadoopversion-IPoIB}.
.4 etc.
.5 hadoop\DTcomment{Hadoop configuration directory}.
.4 logs\DTcomment{Hadoop log directory}.
.4 wordcount\_1\DTcomment{Output directory for the $ 1^{st} $ execution of Wordcount}.
.5 elapsed\_time\DTcomment{Elapsed seconds}.
.5 output\DTcomment{Workload output}.
.5 oprofile\_records\DTcomment{Microarchitecture-level metrics directory}.
.6 log\DTcomment{Oprofile monitoring log}.
.6 sum.csv\DTcomment{Oprofile events summation among the nodes}.
.6 node-0\DTcomment{Node 0 (master) Oprofile statistics directory}.
.6 node-1\DTcomment{Node 1 Oprofile statistics directory}.
.6 ....
.5 rapl\_records\DTcomment{Energy/power monitorization directory}.
.6 log\DTcomment{RAPL graphs generation log}.
.6 gen\_graphs.sh\DTcomment{Script to generate RAPL graphs}. 
.6 avg\DTcomment{Average RAPL statistics directory}.
.6 node-0\DTcomment{Node 0 (master) RAPL statistics directory}.
.6 node-1\DTcomment{Node 1 RAPL statistics directory}.
.6 ....
.5 stat\_records\DTcomment{Resource utilization directory}.
.6 log\DTcomment{Stat graphs generation log}.
.6 gen\_graphs.sh\DTcomment{Script to generate resource utilization graphs}. 
.6 avg\DTcomment{Average statistics directory}.
.6 node-0\DTcomment{Node 0 (master) statistics directory}.
.6 node-1\DTcomment{Node 1 statistics directory}.
.6 ....
.5 bdwatchdog\DTcomment{Temporary files from BDWatchdog daemons}.
.6 Atop\_hostname.err\DTcomment{Error file for atop daemon}.
.6 Atop\_hostname.out\DTcomment{Output file for atop daemon}.
.6 Atop\_hostname.log\DTcomment{Log file for atop daemon}.
.6 ....
.4 wordcount\_2\DTcomment{Output directory for the $ 2^{nd} $ execution of Wordcount}.
.4 ....
.2 9\DTcomment{Output directory for cluster size 9}.
.2 graphs\DTcomment{Performance graphs directory}.
.3 log\DTcomment{Graph generation log}.
.3 wordcount.eps\DTcomment{Time results for the Wordcount benchmark (graph)}.
.3 wordcount.dat\DTcomment{Time results for the Wordcount benchmark (data file)}.
.3 oprofile\DTcomment{Oprofile summary graphs}.
.4 wordcount\DTcomment{Graphs for wordcount}.
.4 ....
.3 rapl\DTcomment{RAPL summary graphs}.
.4 wordcount\DTcomment{Graphs for wordcount}.
.4 ....
}

\caption{\method~output directory structure}

\label{fig:out_structure}

\end{figure}


\subsection{Log \& configuration}

\method~creates separate log and configuration directories for each framework and stores them at \path{{cluster_size}/{framework}}. For example, the configuration directory of Hadoop-\hadoopversion-IPoIB with 5 nodes is \path{5/Hadoop-\hadoopversion-IPoIB/etc/hadoop} and its log directory is \path{5/Hadoop-\hadoopversion-IPoIB/log}. Both directories can be used to check the configuration generated by \method~and the execution of the workloads. Moreover, this feature enables to run simultaneous evaluations of the same framework using different configurations.

\subsection{Performance}

The performance results in terms of time are available in the \path{graphs} subdirectory. For example, for the Wordcount benchmark, they can be found in the \path{graphs/wordcount.eps} file. For each cluster size, the graph depicts the average, maximum and minimum execution times taken by each framework to perform the workload. 


\subsection{Resource utilization}

When using dstat for monitoring resource usage (i.e., ENABLE\_STAT is true), the metrics from the execution of a benchmark are stored at \path{{cluster_size}/{framework}/{benchmark}_{num_execution}/stat_records}. For example, the values of the first execution of Wordcount using Hadoop-\hadoopversion-IPoIB on 5 nodes are at \path{5/Hadoop-\hadoopversion-IPoIB/wordcount_1/stat_records}. This directory contains one subdirectory for the values of each cluster node, plus another one for the average values among the slave nodes. The resource utilization graphs are not automatically generated by \method~in order to prevent the creation of a large number of unnecessary files. The user can generate them by running the script \path{gen_graphs.eps} manually, which contains the command lines needed for generating the resource utilization graphs contained in that directory. These graphs include CPU utilization (\path{cpu_stat.eps}), CPU load (\path{cpu_load_stat.eps}), memory usage (\path{mem_stat.eps}), disk read/write (\path{dsk_sda_rw_stat.eps}), disk utilization (\path{dsk_sda_util_stat.eps}) and network send/recv (\path{net_eth1_stat.eps}, \path{net_ib0_stat.eps}). Disks (sda) and network interfaces (eth1, ib0) are automatically detected by \method. For some resources, like CPU utilization, there are different visualization modes that allow to see the results individually (with lines, \path{cpu_stat.eps}) or as a whole (with stacked values, \path{cpu_stat_stacked.eps}).

When using BDWatchdog for monitoring resource usage (i.e., ENABLE\_BDWATCHDOG is true), the metrics are stored in the OpenTSDB database managed by BDWatchdog. The appropriate REST endpoint for OpenTSDB must be properly configured in \path{bdev-conf.sh}. The time series plots stored in OpenTSDB can be visualized using the BDWatchdog's web interface. Furthermore, the time stamping feature provided by BDWatchdog can be used together with \method~to manage the generation of ``start'' and ``end'' UNIX timestamps for each benchmark. To do so, the MongoDB database managed by BDWatchdog must also be configured properly in \path{bdev-conf.sh} by setting its hostname/IP and port number together with the appropriate REST endpoints. Further information about BDWatchdog can be obtained at \url{https://bdwatchdog.readthedocs.io}.


\subsection{Energy monitoring}

As with resource utilization, energy-related metrics can be found at  \path{{cluster_size}/{framework}/{benchmark}_{num_execution}/rapl_records}. This directory contains one subdirectory with the values for each cluster node, plus another one for the summary values among the slave nodes.

Inside each subdirectory, CSV and graph files are provided for each energy consumption counter detected by \method~in the form of time series. These counters typically include energy and power values for each CPU socket, labeled as package, as well as for PP0 (Power Plane 0 ) and PP1. Separated values for the memory components of each socket are also provided. The summary directory contains the average power values among the slave nodes and their total energy consumption values for each moment. The \path{gen_graphs.eps} script allows to generate the graphs after the evaluation has finished.

Apart from the time series graphs, further energy consumption information is provided to the user in \path{graphs/rapl}, containing a comparison of the energy consumed by each framework during the execution of each workload. Moreover, \method~also obtains energy-performance efficiency ratios that correlate the execution times and the energy consumption of the frameworks, calculated as $ED2P = Energy \  Consumed \times Execution \ Time ^ 2$.

\subsection{Microarchitecture-level metrics}

The results from the microarchitectural monitoring are contained in \path{{cluster_size}/{framework}/{benchmark}_{num_execution}/oprofile_records}. As with the other tools, one subdirectory is provided for each node in the cluster, containing the output of the monitorization. For each hardware counter specified in the configuration parameters, the output shows the total number of events occurred in the system during the execution of the workload. The \path{sum.csv} file contains the total number of events occurred among the slave nodes. These values are used to generate summary graphs for each event, shown in the \path{graphs/oprofile} directory.

\clearpage

\appendix

\section{About Flink configuration}

Recent versions of Flink do not support Hadoop compatibility by default. In order to enable it, the user must configure it manually. Once the desired Flink version has been downloaded and stored in the \path{$BDEv_HOME/solutions/dist/Flink/$flink_version} folder, the flink-hadoop-compatibility jar must be placed inside the \path{lib} folder of the distribution.

\section{About batch-queueing schedulers}

As most clusters and supercomputers use a batch-queuing job scheduler for distributed resource management, \method~is aware of the environment variables and resource constraints that are typically present in these cases. The correct behaviour of \method~under this kind of systems has been tested with Open Grid Scheduler/GE (OGS/GE), Son of Grid Engine (SGE) and Slurm.

\method~will automatically infer from the environment the appropriate compute nodes to use within an interactive/batch job allocation. In this case, no \texttt{HOSTFILE} variable is needed, although it can also be set.

\section{About Modules Environment}

\method~also supports the use of the Modules Environment tool for dynamically modifying the user's environment. If enabled in the configuration, \method~will use it for loading the Java and MPI environment variables.

\section{About Hardware Counters}

When monitoring power consumption, either using the built-in RAPL-based tool included in \method~or using the turbostat tool through BDWatchdog, the cluster nodes must be properly configured to allow regular users to access hardware performance counters. Moreover, the microarchitecture-level monitoring using Oprofile also requires this specific configuration. The following script contains the minimum set of commands that are needed in order to enable this feature in each node of the cluster.

\begin{small}
\begin{lstlisting}
modprobe msr # Load MSR kernel module
chmod 666 /dev/cpu/*/msr # Enable read permisions to MSR registers
echo 0 > /proc/sys/kernel/perf_event_paranoid # Enable access to hardware counters
echo '$USER  ALL=NOPASSWD:/sbin/setcap' >> /etc/sudoers # Allow setcap for the user running BDEv
\end{lstlisting}
\end{small}

Further information about this topic can be obtained at \url{http://icl.cs.utk.edu/projects/papi/wiki/PAPITopics:RAPL_Access}.

\section{About BDWatchdog}

When monitoring energy consumption using turbostat, regular users must have access to hardware performance counters as explained in the previous section. Moreover, the ability of regular users to execute setcap is also needed when monitoring the network traffic using nethogs.

\section{System Requirements}

The following packages need to be installed:

\begin{itemize}
	\item Java JRE 1.8 (or higher)
	\item Expect 1.1 (needed if timeout is enabled)
	\item Gnuplot 4.4 (needed for generating the graphs)
	\item MPI\footnote{DataMPI has been tested with MVAPICH2} (needed for DataMPI)
	\item Oprofile 1.2.0 (needed for microarchitecture-level event counting)
	\item Python 3 (needed for BDWatchdog)
		\begin{itemize}
		\item Required Python modules: python-daemon, requests
		\end{itemize}
	\item turbostat tool (needed for BDWatchdog when enabling turbostat)
\end{itemize}


\section{Contact}

\method~has been developed in the Computer Architecture Group at the University of A Coruña by the following authors:

\begin{itemize}
\item Jorge Veiga: \url{http:gac.udc.es/~jveiga}
\item Roberto R. Exp\'osito: \url{http:gac.udc.es/~rober}
\item Jonatan Enes: \url{http:gac.udc.es/~jonatan}
\item Guillermo L. Taboada: \url{http:gac.udc.es/~gltaboada}
\item Juan Touri\~no: \url{http:gac.udc.es/~juan}
\end{itemize}

To report any question, bug, requirement or information about \method, feel free to contact us at~\url{http://bdev.des.udc.es}.

\end{document}
